# -*- coding: utf-8 -*-
"""Mental Health Risk Classifier.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/18r6ri-ldCc3f9eK--B6xBsXV2zIydi-V
"""

from google.colab import files
uploaded = files.upload()  # Select your mental_health_data.csv

import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, precision_score, confusion_matrix, ConfusionMatrixDisplay
from sklearn.impute import SimpleImputer
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from joblib import dump

# Load data
df = pd.read_csv('Student Mental health.csv')
print("Original data shape:", df.shape)
print("\nFirst 5 rows:")
print(df.head())

# Create 'risk_level' feature
conditions = [
    (df['Do you have Depression?'].eq('Yes') |
     df['Do you have Anxiety?'].eq('Yes') |
     df['Do you have Panic attack?'].eq('Yes')),

    (df['Do you have Depression?'].eq('Yes') &
     df['Do you have Anxiety?'].eq('Yes')),

    (df['Do you have Depression?'].eq('Yes') &
     df['Do you have Anxiety?'].eq('Yes') &
     df['Do you have Panic attack?'].eq('Yes'))
]
choices = ['Medium', 'High', 'Critical']
df['risk_level'] = np.select(conditions, choices, default='Low')

# Convert 'What is your CGPA?' to numerical CGPA
cgpa_mapping = {
    '3.00 - 3.49': 3.25,
    '3.50 - 4.00': 3.75,
    '2.50 - 2.99': 2.75,
    '2.00 - 2.49': 2.25,
    '0 - 1.99': 1.0
}
df['CGPA'] = df['What is your CGPA?'].map(cgpa_mapping)

# Drop unnecessary columns
df = df.drop(['Timestamp', 'Did you seek any specialist for a treatment?', 'What is your CGPA?'], axis=1)

# Extract numerical year of study
df['Your current year of Study'] = df['Your current year of Study'].str.extract('(\d+)').astype(float)

# Encode categorical columns
le = LabelEncoder()
categorical_cols = ['Choose your gender', 'What is your course?',
                    'Marital status', 'Do you have Depression?',
                    'Do you have Anxiety?', 'Do you have Panic attack?', 'risk_level']
for col in categorical_cols:
    if col in df.columns:
        df[col] = le.fit_transform(df[col].astype(str))

# Separate features and target
X = df.drop(['risk_level', 'Do you have Depression?', 'Do you have Anxiety?', 'Do you have Panic attack?'], axis=1)
y = df['risk_level']

# Define numeric and categorical features
numeric_features = ['Age', 'CGPA', 'Your current year of Study']
categorical_features = ['Choose your gender', 'What is your course?',
                        'Marital status']

# Pipelines
numeric_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='median')),
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('imputer', SimpleImputer(strategy='most_frequent')),
    ('encoder', OneHotEncoder(handle_unknown='ignore'))
])

# Preprocessing pipeline
preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ]
)

# Data visualization
plt.figure(figsize=(8,5))
ax = sns.countplot(x=y)
plt.title('Distribution of Risk Levels')
plt.show()

# Train-test split with stratification for better class balance
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Train models
models = {
    "Logistic Regression": LogisticRegression(max_iter=1000),
    "Decision Tree": DecisionTreeClassifier(),
    "Random Forest": RandomForestClassifier()
}

results = []

for name, model in models.items():
    pipeline = Pipeline(steps=[
        ('preprocessor', preprocessor),
        ('classifier', model)
    ])

    pipeline.fit(X_train, y_train)
    y_pred = pipeline.predict(X_test)

    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')

    results.append({
        'Model': name,
        'Accuracy': accuracy,
        'Precision': precision
    })

    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm,
                                  display_labels=np.unique(y))
    disp.plot()
    plt.title(f'Confusion Matrix - {name}')
    plt.show()

# Model Performance
results_df = pd.DataFrame(results)
print("\nModel Performance Comparison:")
print(results_df)

# Save best model (Random Forest)
best_model = RandomForestClassifier()
final_pipeline = Pipeline(steps=[
    ('preprocessor', preprocessor),
    ('classifier', best_model)
])
final_pipeline.fit(X_train, y_train)
dump(final_pipeline, 'model.pkl')
print("âœ… Best model saved as model.pkl")